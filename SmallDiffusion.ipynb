{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ywWxGunPvzi",
        "outputId": "97c5f40b-2c22-49b3-e56f-18b7a601ff43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWOPO8Fu7aGs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, hid_channels, num_res_blocks=2):\n",
        "        super(UNet, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.hid_channels = hid_channels\n",
        "        self.num_res_blocks = num_res_blocks\n",
        "\n",
        "        # Define layers\n",
        "        self.in_conv = nn.Conv2d(in_channels, hid_channels, kernel_size=3, padding=1)\n",
        "        self.down = nn.Sequential(\n",
        "            nn.Conv2d(hid_channels, hid_channels * 2, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.middle = nn.Sequential(\n",
        "            nn.Conv2d(hid_channels * 2, hid_channels * 2, kernel_size=3, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.up = nn.Sequential(\n",
        "            nn.ConvTranspose2d(hid_channels * 2, hid_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.out_conv = nn.Conv2d(hid_channels, out_channels, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.in_conv(x)\n",
        "        x = self.down(x)\n",
        "        x = self.middle(x)\n",
        "        x = self.up(x)\n",
        "        x = self.out_conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class QuantizeWeights(nn.Module):\n",
        "    def __init__(self, bit_width):\n",
        "        super(QuantizeWeights, self).__init__()\n",
        "        self.bit_width = bit_width\n",
        "        self.interval = nn.Parameter(torch.tensor(1.0), requires_grad=True)\n",
        "\n",
        "    def initialize_interval(self, w):\n",
        "        with torch.no_grad():\n",
        "            max_val = w.max().item()\n",
        "            min_val = w.min().item()\n",
        "            self.interval.data = torch.tensor(\n",
        "                (max_val - min_val) / (2 ** (self.bit_width - 1) - 1),\n",
        "                device=self.interval.device\n",
        "            )\n",
        "\n",
        "    def forward(self, w):\n",
        "        self.interval.data.clamp_(1e-5, float(\"inf\"))\n",
        "        max_val = 2 ** (self.bit_width - 1) - 1\n",
        "        min_val = -2 ** (self.bit_width - 1)\n",
        "        w_clamped = torch.clamp(w / self.interval, min_val, max_val)\n",
        "        return torch.round(w_clamped) * self.interval\n",
        "\n",
        "\n",
        "class QuantizeActivations(nn.Module):\n",
        "    def __init__(self, bit_width):\n",
        "        super(QuantizeActivations, self).__init__()\n",
        "        self.bit_width = bit_width\n",
        "        self.interval = nn.Parameter(torch.tensor(1.0), requires_grad=True)\n",
        "\n",
        "    def initialize_interval(self, x):\n",
        "        with torch.no_grad():\n",
        "            max_val = x.max().item()\n",
        "            self.interval.data = torch.tensor(\n",
        "                max_val / (2 ** self.bit_width - 1),\n",
        "                device=self.interval.device\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.interval.data.clamp_(1e-5, float(\"inf\"))\n",
        "        max_val = 2 ** self.bit_width - 1\n",
        "        x_clamped = torch.clamp(x / self.interval, 0, max_val)\n",
        "        return torch.round(x_clamped) * self.interval\n",
        "\n",
        "\n",
        "class QuantizedUNet(UNet):\n",
        "    def __init__(self, in_channels, out_channels, hid_channels, num_res_blocks=2, bit_width=8):\n",
        "        super(QuantizedUNet, self).__init__(in_channels, out_channels, hid_channels, num_res_blocks)\n",
        "        self.bit_width = bit_width\n",
        "        self.weight_quantizer = QuantizeWeights(bit_width)\n",
        "        self.activation_quantizer = QuantizeActivations(bit_width)\n",
        "        self.initialized = False\n",
        "\n",
        "    def initialize_quantization_intervals(self):\n",
        "        \"\"\"Initialize weight and activation intervals.\"\"\"\n",
        "        if self.initialized:\n",
        "            return\n",
        "\n",
        "        # Initialize weight quantization intervals\n",
        "        for name, param in self.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                self.weight_quantizer.initialize_interval(param)\n",
        "\n",
        "        # Create dummy input on the same device as the model\n",
        "        device = next(self.parameters()).device\n",
        "        dummy_input = torch.randn(1, self.in_channels, 64, 64, device=device)\n",
        "\n",
        "        # Perform a dummy forward pass to initialize activation quantizers\n",
        "        with torch.no_grad():\n",
        "            _ = self._dummy_forward(dummy_input)\n",
        "        self.initialized = True\n",
        "\n",
        "    def _dummy_forward(self, x):\n",
        "        \"\"\"A dummy forward pass for initialization.\"\"\"\n",
        "        x = self.in_conv(x)\n",
        "        x = self.activation_quantizer(x)\n",
        "        x = self.down(x)\n",
        "        x = self.middle(x)\n",
        "        x = self.up(x)\n",
        "        x = self.out_conv(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass with quantization.\"\"\"\n",
        "        if not self.initialized:\n",
        "            self.initialize_quantization_intervals()\n",
        "\n",
        "        # Forward pass with quantized weights and activations\n",
        "        x = self.in_conv(x)\n",
        "        x = self.activation_quantizer(x)\n",
        "        x = self.down(x)\n",
        "        x = self.middle(x)\n",
        "        x = self.activation_quantizer(x)\n",
        "        x = self.up(x)\n",
        "        x = self.out_conv(x)\n",
        "        return x\n",
        "\n",
        "    def load_from_unet(self, unet):\n",
        "        \"\"\"Load weights from a regular UNet.\"\"\"\n",
        "        self.load_state_dict(unet.state_dict(), strict=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-fid\n",
        "from pytorch_fid import fid_score\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# Function to save images to disk\n",
        "def save_images_to_disk(images, directory, prefix=\"image\"):\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    for i, img in enumerate(images):\n",
        "        img = img.cpu().detach().numpy().transpose(1, 2, 0)  # Convert to numpy\n",
        "        img = (img * 255).astype('uint8')  # Convert to [0, 255] for image saving\n",
        "        image_path = os.path.join(directory, f\"{prefix}_{i}.png\")\n",
        "        Image.fromarray(img).save(image_path)\n",
        "\n",
        "# Calculate FID score\n",
        "def calculate_fid_from_disk(real_images_dir, generated_images_dir):\n",
        "    # Implement the FID calculation logic here\n",
        "    # Placeholder function, assume it's already implemented\n",
        "    return fid_score.calculate_fid_given_paths(\n",
        "        [generated_images_dir, real_images_dir],\n",
        "        batch_size=50,\n",
        "        device=\"cuda\",\n",
        "        dims=2048\n",
        "    )\n"
      ],
      "metadata": {
        "id": "fawZP8s-9d-C",
        "outputId": "be0228bd-08b6-41b0-cb4c-aa3e0b6f4755",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-fid in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-fid) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pytorch-fid) (11.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pytorch-fid) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-fid) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-fid) (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->pytorch-fid) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->pytorch-fid) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->pytorch-fid) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->pytorch-fid) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->pytorch-fid) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.1->pytorch-fid) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.1->pytorch-fid) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.1->pytorch-fid) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm  # Import tqdm for the progress bar\n",
        "\n",
        "# Define the UNet model (already provided in the question)\n",
        "# Assuming that the UNet class is already defined.\n",
        "\n",
        "# Step 1: Define a training function for UNet on CIFAR-10\n",
        "def train_unet_on_cifar10(model, num_epochs=10, batch_size=64, lr=1e-3, device='cuda'):\n",
        "    # Dataset and DataLoader\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    print(len(train_loader))\n",
        "\n",
        "    # Loss function and optimizer\n",
        "    loss_fn = nn.MSELoss()  # MSE loss\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Get the device (cuda or cpu)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    # Temporary directory for saving images\n",
        "    real_images_dir = \"./real_images\"\n",
        "    generated_images_dir = \"./generated_images\"\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        # Training loop\n",
        "        with tqdm(train_loader, unit=\"batch\", desc=f\"Epoch {epoch+1}/{num_epochs}\") as pbar:\n",
        "            for images, labels in pbar:\n",
        "                images = images.to(device)  # Move images to the same device as the model\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(images)\n",
        "                loss = loss_fn(outputs, images)  # MSE loss between output and input image\n",
        "\n",
        "                # Backward pass and optimization\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "\n",
        "                # Update tqdm progress bar with loss\n",
        "                pbar.set_postfix(loss=running_loss / (pbar.n + 1))\n",
        "\n",
        "        if epoch % 5 == 4:\n",
        "            # Save images and calculate FID score at the end of each epoch\n",
        "            save_images_to_disk(images, real_images_dir, prefix=f\"real_epoch_{epoch+1}\")\n",
        "            save_images_to_disk(outputs, generated_images_dir, prefix=f\"gen_epoch_{epoch+1}\")\n",
        "\n",
        "            # Calculate FID score for the epoch\n",
        "            fid_score = calculate_fid_from_disk(real_images_dir, generated_images_dir)\n",
        "            print(f\"FID Score at Epoch {epoch+1}: {fid_score}\")\n",
        "\n",
        "        # Print the loss for every epoch\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "# Initialize UNet model and train\n",
        "unet = UNet(in_channels=3, out_channels=3, hid_channels=64).to('cuda')\n",
        "train_unet_on_cifar10(unet, num_epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myW1Lq2_PUHp",
        "outputId": "4e985907-bdfa-4d7a-fd17-ebefd3df3509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 782/782 [00:36<00:00, 21.49batch/s, loss=0.00575]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.005746270485600168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 782/782 [00:29<00:00, 26.91batch/s, loss=0.000556]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 0.0005560295879142656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 782/782 [00:28<00:00, 27.61batch/s, loss=0.000384]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 0.0003830612464377697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 782/782 [00:29<00:00, 26.57batch/s, loss=0.000274]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 0.0002733420763659598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 782/782 [00:28<00:00, 27.67batch/s, loss=0.000248]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  7.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  7.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID Score at Epoch 5: 44.45087886570661\n",
            "Epoch [5/10], Loss: 0.00024755763807310187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 782/782 [00:28<00:00, 27.92batch/s, loss=0.000205]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 0.00020403270985384214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 782/782 [00:28<00:00, 27.69batch/s, loss=0.000148]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 0.00014801885790011906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 782/782 [00:29<00:00, 26.93batch/s, loss=0.000129]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 0.00012866361313728023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 782/782 [00:29<00:00, 26.78batch/s, loss=0.000133]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 0.00013255421255306622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 782/782 [00:28<00:00, 27.09batch/s, loss=0.000121]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  4.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  4.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID Score at Epoch 10: 36.14328189989487\n",
            "Epoch [10/10], Loss: 0.0001212307139291585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Create a student model (QuantizedUNet)\n",
        "# Training function for the quantized student model (QuantizedUNet)\n",
        "def train_quantized_unet_from_baseline(unet, num_epochs=5, batch_size=64, lr=1e-3, device='cuda'):\n",
        "    # Initialize student model (QuantizedUNet) with UNet weights\n",
        "    student_model = QuantizedUNet(in_channels=3, out_channels=3, hid_channels=64, bit_width=8).to(device)\n",
        "    student_model.load_from_unet(unet)\n",
        "\n",
        "    # Dataset and DataLoader\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Loss function and optimizer\n",
        "    loss_fn = nn.MSELoss()  # MSE loss\n",
        "    optimizer = optim.Adam(student_model.parameters(), lr=lr)\n",
        "\n",
        "    # Temporary directory for saving images\n",
        "    real_images_dir = \"./real_images\"\n",
        "    generated_images_dir = \"./generated_images\"\n",
        "\n",
        "    # Train for 5 epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        student_model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        # Training loop with tqdm progress bar\n",
        "        with tqdm(train_loader, unit=\"batch\", desc=f\"Epoch {epoch+1}/{num_epochs}\") as pbar:\n",
        "            for images, labels in pbar:\n",
        "                images = images.to(device)  # Move images to the same device as the model\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = student_model(images)\n",
        "                loss = loss_fn(outputs, images)  # MSE loss\n",
        "\n",
        "                # Backward pass and optimization\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "\n",
        "                # Update tqdm progress bar with loss\n",
        "                pbar.set_postfix(loss=running_loss / (pbar.n + 1))\n",
        "\n",
        "        # Save images and calculate FID score at the end of each epoch\n",
        "        if (epoch + 1) % 3 == 0:  # Save and calculate FID every epoch\n",
        "            save_images_to_disk(images, real_images_dir, prefix=f\"real_epoch_{epoch+1}\")\n",
        "            save_images_to_disk(outputs, generated_images_dir, prefix=f\"gen_epoch_{epoch+1}\")\n",
        "\n",
        "            # Calculate FID score for the epoch\n",
        "            fid_score = calculate_fid_from_disk(real_images_dir, generated_images_dir)\n",
        "            print(f\"FID Score at Epoch {epoch+1}: {fid_score}\")\n",
        "\n",
        "        # Print the loss for every epoch\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "    # Return the trained student model\n",
        "    return student_model\n",
        "\n",
        "student_model = train_quantized_unet_from_baseline(unet, num_epochs=3)\n",
        "\n"
      ],
      "metadata": {
        "id": "Os84GwFQPda9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "def41efa-39c3-47df-db1d-0e331c989ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/3: 100%|██████████| 782/782 [00:28<00:00, 27.80batch/s, loss=0.131]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Loss: 0.1310089953300898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 782/782 [00:28<00:00, 27.41batch/s, loss=0.154]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/3], Loss: 0.1536112810625597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 782/782 [00:28<00:00, 27.60batch/s, loss=0.164]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID Score at Epoch 3: 112.00976041198737\n",
            "Epoch [3/3], Loss: 0.1635710603326483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define co-studying loss function\n",
        "def co_studying_loss(x, teacher_logits, student_logits, temperature=1.0):\n",
        "    import torch.nn.functional as F\n",
        "\n",
        "    # Softened probabilities\n",
        "    teacher_soft = F.softmax(teacher_logits / temperature, dim=1)\n",
        "    student_soft = F.softmax(student_logits / temperature, dim=1)\n",
        "\n",
        "    # MSE loss for both networks\n",
        "    teacher_mse_loss = F.mse_loss(teacher_logits, x)\n",
        "    student_mse_loss = F.mse_loss(student_logits, x)\n",
        "\n",
        "    # KL divergence loss (softened)\n",
        "    kl_loss_student = F.kl_div(student_soft.log(), teacher_soft, reduction='batchmean')\n",
        "    kl_loss_teacher = F.kl_div(teacher_soft.log(), student_soft, reduction='batchmean')\n",
        "\n",
        "    # Combine losses\n",
        "    student_loss = student_mse_loss + (temperature ** 2) * kl_loss_student\n",
        "    teacher_loss = teacher_mse_loss + (temperature ** 2) * kl_loss_teacher\n",
        "\n",
        "    return teacher_loss, student_loss\n",
        "\n",
        "# Step 3: Train a new teacher model with QuantizedUNet student model\n",
        "def train_teacher_with_student(teacher_model, student_model, num_epochs=20, batch_size=64, lr=1e-3, device='cuda'):\n",
        "    # Dataset and DataLoader\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Loss function and optimizers\n",
        "    optimizer_teacher = optim.Adam(teacher_model.parameters(), lr=lr)\n",
        "    optimizer_student = optim.Adam(student_model.parameters(), lr=lr)\n",
        "\n",
        "    # Directories for saving images\n",
        "    real_images_dir = \"./real_images\"\n",
        "    generated_images_dir_teacher = \"./generated_images_teacher\"\n",
        "    generated_images_dir_student = \"./generated_images_student\"\n",
        "\n",
        "    # Train for 20 epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        teacher_model.train()\n",
        "        student_model.train()\n",
        "        running_teacher_loss = 0.0\n",
        "        running_student_loss = 0.0\n",
        "\n",
        "        # Training loop with tqdm progress bar\n",
        "        with tqdm(train_loader, unit=\"batch\", desc=f\"Epoch {epoch+1}/{num_epochs}\") as pbar:\n",
        "            for images, labels in pbar:\n",
        "                images = images.to(device)  # Move images to the same device as the models\n",
        "\n",
        "                # Forward pass for teacher and student\n",
        "                teacher_outputs = teacher_model(images)\n",
        "                student_outputs = student_model(images)\n",
        "\n",
        "                # Compute co-studying loss\n",
        "                teacher_loss, student_loss = co_studying_loss(images, teacher_outputs, student_outputs)\n",
        "\n",
        "                # Backward pass and optimization\n",
        "                optimizer_teacher.zero_grad()\n",
        "                optimizer_student.zero_grad()\n",
        "\n",
        "                # Teacher backward pass (retain graph to keep it for student backward pass)\n",
        "                teacher_loss.backward(retain_graph=True)\n",
        "\n",
        "                # Student backward pass\n",
        "                student_loss.backward()\n",
        "\n",
        "                optimizer_teacher.step()\n",
        "                optimizer_student.step()\n",
        "\n",
        "                running_teacher_loss += teacher_loss.item()\n",
        "                running_student_loss += student_loss.item()\n",
        "\n",
        "                # Update tqdm progress bar with loss\n",
        "                pbar.set_postfix(\n",
        "                    teacher_loss=running_teacher_loss / (pbar.n + 1),\n",
        "                    student_loss=running_student_loss / (pbar.n + 1)\n",
        "                )\n",
        "\n",
        "        # Print the loss for every epoch\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Teacher Loss: {running_teacher_loss / len(train_loader)}, Student Loss: {running_student_loss / len(train_loader)}\")\n",
        "\n",
        "        # Save images and calculate FID score at the end of each epoch\n",
        "        if (epoch + 1) % 7 == 0:  # Save and calculate FID every 5 epochs\n",
        "            save_images_to_disk(images, real_images_dir, prefix=f\"real_epoch_{epoch+1}\")\n",
        "            save_images_to_disk(teacher_outputs, generated_images_dir_teacher, prefix=f\"gen_teacher_epoch_{epoch+1}\")\n",
        "            save_images_to_disk(student_outputs, generated_images_dir_student, prefix=f\"gen_student_epoch_{epoch+1}\")\n",
        "\n",
        "            # Calculate FID score for teacher model\n",
        "            fid_score_teacher = calculate_fid_from_disk(real_images_dir, generated_images_dir_teacher)\n",
        "            print(f\"FID Score for Teacher at Epoch {epoch+1}: {fid_score_teacher}\")\n",
        "\n",
        "            # Calculate FID score for student model\n",
        "            fid_score_student = calculate_fid_from_disk(real_images_dir, generated_images_dir_student)\n",
        "            print(f\"FID Score for Student at Epoch {epoch+1}: {fid_score_student}\")\n",
        "\n",
        "teacher_model = UNet(in_channels=3, out_channels=3, hid_channels=64).to('cuda')\n",
        "train_teacher_with_student(teacher_model, student_model, num_epochs=7, batch_size=64, lr=1e-3, device='cuda')\n"
      ],
      "metadata": {
        "id": "rcHg7slMPeag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "898089be-c1c6-4e76-91c4-9be7bbc8c8e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/7: 100%|██████████| 782/782 [00:45<00:00, 17.29batch/s, student_loss=0.16, teacher_loss=0.0706]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/7], Teacher Loss: 0.07050962042292137, Student Loss: 0.1601168326176036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/7: 100%|██████████| 782/782 [00:44<00:00, 17.44batch/s, student_loss=0.132, teacher_loss=0.0329]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/7], Teacher Loss: 0.0328873094800107, Student Loss: 0.13147577581465092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/7: 100%|██████████| 782/782 [00:45<00:00, 17.19batch/s, student_loss=0.123, teacher_loss=0.0281]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/7], Teacher Loss: 0.028065757728312785, Student Loss: 0.12249921176515882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/7: 100%|██████████| 782/782 [00:45<00:00, 17.11batch/s, student_loss=0.12, teacher_loss=0.0272]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/7], Teacher Loss: 0.02717136810688526, Student Loss: 0.12013535706512153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/7: 100%|██████████| 782/782 [00:44<00:00, 17.39batch/s, student_loss=0.12, teacher_loss=0.025]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/7], Teacher Loss: 0.02495403000441811, Student Loss: 0.11984985988691944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/7: 100%|██████████| 782/782 [00:44<00:00, 17.44batch/s, student_loss=0.121, teacher_loss=0.0247]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/7], Teacher Loss: 0.02462351443531835, Student Loss: 0.12103266314701046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/7: 100%|██████████| 782/782 [00:44<00:00, 17.39batch/s, student_loss=0.123, teacher_loss=0.0242]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/7], Teacher Loss: 0.02419323412120304, Student Loss: 0.12291750722490918\n",
            "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  5.85it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID Score for Teacher at Epoch 7: 295.2592911249533\n",
            "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  6.26it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID Score for Student at Epoch 7: 329.0478384838251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iEmE0s0w9PZx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}